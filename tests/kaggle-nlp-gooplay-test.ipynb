{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "\n",
    "# We need three NLP imports. The first is nltk, the second is \n",
    "# the set of stopwords from nltk's corpus, and the third is \n",
    "# the count vectorizer from sklearn. \n",
    "\n",
    "\n",
    "# Import sklearn's train test split functionality. \n",
    "\n",
    "\n",
    "# We'll need a confusion matrix from metrics. \n",
    "\n",
    "\n",
    "# We'll be using three models, a Gaussian naive bayes, a random\n",
    "# forest classifier, and a logistic regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user_review data\n",
    "\n",
    "data = pd.read_csv(\"Data/google-play-store-apps/googleplaystore_user_reviews.csv\",encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .info(), .head(), and .describe() to get a handle on the \n",
    "# the data. Find out how many null values there are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do things to data to get it into the format\n",
    "# we want. First, reduce data to just the \"Translated_Review\"\n",
    "# and \"Sentiment\" columns. Then, drop the null values. \n",
    "\n",
    "# The first can be accomplished with pd.concat(), don't forget the \n",
    "# axis argument for BOTH steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, use a list comprehension to map the \"Sentiment\" values\n",
    "# as follows: \"Positive\" == 0, \"Negative\" == 1, \"Neutral\" == 2\n",
    "\n",
    "# Use seaborn's countplot to figure out how many of each \n",
    "# value are in \"Sentiment\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a lemmatizer object in the var 'lemma'.\n",
    "\n",
    "# Now we need to process \"Translated_Review\". Fill in the blanks:\n",
    "\n",
    "# text_list = []\n",
    "# for i in data[\"Translated_Review\"]:\n",
    "#     text = re.___('[^a-zA-Z]', \" \", i)\n",
    "#     text = text._____() # --> make it lowercase \n",
    "#     text = nltk.____________(text) # --> tokenize\n",
    "#     text = [lemma._________(word) for word in text] # --> lemmatize \n",
    "#     text = \" \".join(text)\n",
    "#     text_list.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a count vectorizer, max features 1000\n",
    "\n",
    "# Make a var 'sparse_matrix' with the count vectorizer .fit_transform() \n",
    "# method and the text_list, and make it an array. # Make a var \"all_words\" equal to the \n",
    "# feature_names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, our train test split. Make vars \"x\" and \"y\", equal to \n",
    "# sparse matrix and the values from \"Sentiment\" (which is the column at index\n",
    "# 1), respectively.\n",
    "\n",
    "# Then make a train test split with them, random_state = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to build naive bayes, random forest classifier, \n",
    "# and logistic regression. \n",
    "\n",
    "# For each instantiate the class object in a suitable variable\n",
    "# name, fit each on the training data, then print the accuracy\n",
    "# score on the test data. The only snag here is that \n",
    "# RandomForestClassifier() requires n_estimators and \n",
    "# random_state = 42 arguments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to print out the confusion matrix for each \n",
    "# of the three models above:\n",
    "\n",
    "# y_pred = nb.predict(X_test)\n",
    "\n",
    "# names = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# f,ax = plt.subplots(figsize = (5,5))\n",
    "# sns.heatmap(cm, annot=True, linewidth = .5, linecolor = 'r', fmt = '.0f', ax=ax)\n",
    "\n",
    "# plt.xlabel('y_pred')\n",
    "# plt.ylabel('y_true')\n",
    "# ax.set_xticklabels(names)\n",
    "# ax.set_yticklabels(names)\n",
    "# plt.show()\n",
    "\n",
    "# But substitute in the right model variable name in place \n",
    "# of nb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
